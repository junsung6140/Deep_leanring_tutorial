{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fashion_Mnist_practice.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNHd/Y/WmTd+J80E42wD1U0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/junsung6140/Deep_leanring_tutorial/blob/main/Fashion_Mnist_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRNRZ0gTvW06"
      },
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CON44dRvjf_"
      },
      "source": [
        "# 전체 6만개 데이터 중, 5만개는 학습 데이터용, 1만개는 테스트 데이터용으로 분리\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "# image size는 28x28의 grayscale 2차원 데이터\n",
        "print(\"train dataset shape:\", train_images.shape, train_labels.shape)\n",
        "print(\"test dataset shape:\", test_images.shape, test_labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghNanEy-v_ml"
      },
      "source": [
        "## Mnist data 시각화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHGlTfEkvtbk"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.imshow(train_images[0], cmap='gray')\n",
        "plt.title(train_labels[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9_GUXhgwIxK"
      },
      "source": [
        "train_images[0, :, :], train_labels[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xc324LgGwPET"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat','Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "def show_images(images, labels, ncols=8):\n",
        "    figure, axs = plt.subplots(figsize=(22, 6), nrows=1, ncols=ncols) # 1행 ncols열 플랏을 만듬\n",
        "    for i in range(ncols):\n",
        "        axs[i].imshow(images[i], cmap='gray')\n",
        "        axs[i].set_title(class_names[labels[i]])\n",
        "        \n",
        "show_images(train_images[:8], train_labels[:8], ncols=8)\n",
        "show_images(train_images[8:16], train_labels[8:16], ncols=8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvRmJl1AxIlA"
      },
      "source": [
        "## 데이터 전처리 수행\n",
        " * 0 ~ 255 사이의 픽셀값을 0~1 사이 값으로 변환 (보통 큰 값보다 0부터 1 사이 값이 결과가 잘나오는 경우가 많다)\n",
        " * array type은 float 32"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yebHERAwe6w"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "def get_preprocessed_data(images, labels):\n",
        "    \n",
        "    # 학습과 테스트 이미지 array를 0~1 사이값으로 scale 및 float32 형 변형. \n",
        "    images = np.array(images/255.0, dtype=np.float32)\n",
        "    labels = np.array(labels, dtype=np.float32)\n",
        "    \n",
        "    return images, labels\n",
        "\n",
        "train_images, train_labels = get_preprocessed_data(train_images, train_labels)\n",
        "test_images, test_labels = get_preprocessed_data(test_images, test_labels)\n",
        "\n",
        "print(\"train dataset shape:\", train_images.shape, train_labels.shape)\n",
        "print(\"test dataset shape:\", test_images.shape, test_labels.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rK9_GOwLx4zX"
      },
      "source": [
        "train_images[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJHNF7c4x3RL"
      },
      "source": [
        "## Dense Layer를 기반으로 모델을 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxCMXsCvxsNW"
      },
      "source": [
        "INPUT_SIZE= train_images.shape[1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P35RsB_QyIOe"
      },
      "source": [
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=INPUT_SIZE), # 2차원 데이터를 dense로 학습하기 위해 flatten을 해준다 \n",
        "    Dense(100, activation='relu'),\n",
        "    Dense(30, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Jiw18ViyWcK"
      },
      "source": [
        "### 모델의 Loss와 Optimizer 설정하고 학습을 수행\n",
        "* loss는 categorical_corssentropy로, optimizer는 Adam으로 설정\n",
        "* cotegorical crossentropy를 위해서 Lable을 One Hot Encoding으로 변경"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0fRghX8yOxA"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import Accuracy\n",
        "\n",
        "model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onJdevMr0H9k"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "train_oh_labels = to_categorical(train_labels)\n",
        "test_oh_labels = to_categorical(test_labels)\n",
        "\n",
        "print(train_oh_labels.shape, test_oh_labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzLqEP730WeD"
      },
      "source": [
        "train_images.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hkdLTM_0YmN"
      },
      "source": [
        "history = model.fit(x=train_images, y=train_oh_labels, batch_size=32, epochs=20, verbose=1)\n",
        "## batch size는 32, 64 정도의 mini batch가 학습효과가 좋다고 알려져 있다. \n",
        "# batch size가 클수를 안정적으로 학습이 된다\n",
        "# batch size가 작을 수록 필요한 메모리가 감소된다는 장점이 있다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlJVSyQ60huL"
      },
      "source": [
        "print(history.history['loss'])\n",
        "print(history.history['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eDKCCJH20WK"
      },
      "source": [
        "## 테스트 data를 기반으로 Label 예측\n",
        "- model.predcit()를 이용하여 label 예측\n",
        "- predict() 인자로 입력되는 feature array는 학습의 feature array와 shape이 동일해야함\n",
        "- fit() 시 3차원 array로 입력 햇으므로 predict()도 동일한 3차원 데이터 입력\n",
        "- 특히 한건만 predict() 할때도 3차원 데이터 여야함. 이를 위해 expand_dims()로 2차원 데이터를 3차원으로 변경"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHd9xp9M1EK8"
      },
      "source": [
        "test_images.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKJQiaUl3TjW"
      },
      "source": [
        "pred_proba = model.predict(test_images)\n",
        "print(pred_proba.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_leGH1kL3Vfk"
      },
      "source": [
        "pred_proba = model.predict(np.expand_dims(test_images[0], axis=0))\n",
        "print('softmax output:', pred_proba)\n",
        "pred = np.argmax(np.squeeze(pred_proba))\n",
        "print('predicted class value:', pred)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QXSMKVb3W0h"
      },
      "source": [
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat','Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "print('target class value:', test_labels[0], 'predicted class value:', pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePe6TjPK3pll"
      },
      "source": [
        "## 테스트 데이터 세트로 모델 성능 검증"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LA92p0RX3hU0"
      },
      "source": [
        "model.evaluate(test_images, test_oh_labels, batch_size= 64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HYhOySrI0y9"
      },
      "source": [
        "## 검증 데이터 세트를 이용하여 학습 수행\n",
        "- 일반적으로 fit()수행시 별도의 검증 데이텉 세트를 이용하여 학습 시 overfitting이 발생하는지 모니터링\n",
        "- fit()을 수행하면 iteration을반복하기 때문에 중간에 파라미터 변경등의 작업이 어려움\n",
        "- fit() iteration시 여러 작업을 하기 위해 callback객체를 가짐\n",
        "- 검증 데이터 세트를 fit()시 적용하여 과적합이나 더이상 검증 데이터 성능이 좋아지지 않을 때 callback을 사용하여 learning rate 보정 작업 등을 수행 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvvowFYj3xmb"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 기존 학습 데이터를 다시 학습과 검증 데이터 세트로 분리\n",
        "tr_images, val_images, tr_labels, val_labels = train_test_split(train_images, train_labels, test_size=0.15, random_state=2021)\n",
        "print('train과 validation shape:', tr_images.shape, tr_labels.shape, val_images.shape, val_labels.shape)\n",
        "\n",
        "# OHE 적용\n",
        "tr_oh_labels = to_categorical(tr_labels)\n",
        "val_oh_labels = to_categorical(val_labels)\n",
        "\n",
        "print('after OHE:', tr_oh_labels.shape, val_oh_labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBJkEy3aJyaK"
      },
      "source": [
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "INPUT_SIZE = 28\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(INPUT_SIZE, INPUT_SIZE)),\n",
        "    Dense(100, activation='relu'),\n",
        "    Dense(30, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEf3Up4ZKA6s"
      },
      "source": [
        "history = model.fit(x=tr_images, y=tr_oh_labels, batch_size=128, validation_data=(val_images, val_oh_labels), \n",
        "                    epochs=20, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diJ1ClajKDNY"
      },
      "source": [
        "print(history.history['loss'])\n",
        "print(history.history['accuracy'])\n",
        "print(history.history['val_loss'])\n",
        "print(history.history['val_accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXgmISwwKKSh"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='train')\n",
        "plt.plot(history.history['val_accuracy'], label='valid')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EG65h_rfKw_B"
      },
      "source": [
        "## Functional API\n",
        "- 취미로 할거 아니면 꼭 알아둬야함\n",
        "- Sequential을 이용하면 쉽게 모델을 만들 수 잇음\n",
        "- 하지만 keras Framework의 핵심은 Functional API의 핵심이다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vE6bD2k7KMWF"
      },
      "source": [
        "# Sequential Model을 이용하여 Keras 모델 생성 \n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "INPUT_SIZE = 28\n",
        "\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(INPUT_SIZE, INPUT_SIZE)),\n",
        "    Dense(100, activation='relu'),\n",
        "    Dense(30, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQYq0pcuLw68"
      },
      "source": [
        "from tensorflow.keras.layers import Input, Flatten, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "## 객체를 만들어준 후 생성자를 만들어 layer를 만듬\n",
        "\n",
        "input_tensor = Input(shape=(INPUT_SIZE, INPUT_SIZE))\n",
        "x = Flatten()(input_tensor)\n",
        "x = Dense(100, activation='relu')(x)\n",
        "x = Dense(30, activation='relu')(x)\n",
        "output = Dense(10, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=input_tensor, outputs=output)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NR_vUQNNDU6"
      },
      "source": [
        "## Custom 한 Dense Layer 생성하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4rPM3pMLyj_"
      },
      "source": [
        "from tensorflow.keras.layers import Layer, Input\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow as tf\n",
        "\n",
        "class CustomDense(tf.keras.layers.Layer):\n",
        "    def __init__(self, units= 32):\n",
        "      super(CustomDense, self).__init__()\n",
        "      self.units= units\n",
        "\n",
        "    def build(self, input_shape):\n",
        "      self.w= self.add_weight(\n",
        "          shape= (input_shape[-1], self.units),\n",
        "          initializer= 'random_normal',\n",
        "          trainable= True,\n",
        "      )\n",
        "      self.b= self.add_weight(\n",
        "          shape= (self.units,), initializer= 'random_normal', trainable= True,\n",
        "      )\n",
        "\n",
        "      # CustomDense 객체에 callable로 입력된 입력 데이터 처리\n",
        "    def call(self, inputs):\n",
        "      return tf.matmul(inputs, self.w)+ self.b\n",
        "\n",
        "  # input 값을 4개의 원소를 가지는 1차원 으로 생성\n",
        "inputs= Input((4,))\n",
        "  # 10개의 unit을 가지는 CustomDense 객체를 생성 후 callable로 inputs값 입력\n",
        "outputs= CustomDense(10)(inputs)\n",
        "\n",
        "  # inputs와 outputs로 model 생성\n",
        "model= Model(inputs, outputs)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeYMDvWid2gw"
      },
      "source": [
        "# 함수화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9Brn5-Nd2OC"
      },
      "source": [
        "from tensorflow.keras.layers import Layer, Input, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow as tf\n",
        "\n",
        "INPUT_SIZE= 28\n",
        "\n",
        "def create_model():\n",
        "  input_tensor = Input(shape= (INPUT_SIZE, INPUT_SIZE))\n",
        "  x= Flatten()(input_tensor)\n",
        "  x= Dense(100, activation= 'relu')(x)\n",
        "  x= Dense(50, activation='relu')(x)\n",
        "  output= Dense(10, activation= 'softmax')(x)\n",
        "\n",
        "  model= Model(inputs= input_tensor, outputs= output)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoWS2cgISnng"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 0~1 사이값의 float32로 변경하는 함수\n",
        "def get_preprocessed_data(images, labels):\n",
        "  # 학습과 테스트 이미지 array를 0~1 사이값으로 scale 및 float32 형 변경\n",
        "  images= np.array(images/255.0, dtype=np.float32)\n",
        "  labels= np.array(labels, dtype= np.float32)\n",
        "\n",
        "  return images, labels\n",
        "\n",
        "# 0~1 사이값 float32 변경하는 함수 호출 한 뒤 ohe 적용\n",
        "def get_preprocessed_ohe(images, labels):\n",
        "  images, labels= get_preprocessed_data(images, labels)\n",
        "  # one hot encoding 적용\n",
        "  oh_labels= to_categorical(labels)\n",
        "  return images, oh_labels\n",
        "\n",
        "# 학습/검증/테스트 데이터 세트에 전처리 및 OHE 적용한 뒤 반환 \n",
        "def get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021):\n",
        "    # 학습 및 테스트 데이터 세트를  0 ~ 1사이값 float32로 변경 및 OHE 적용. \n",
        "    train_images, train_oh_labels = get_preprocessed_ohe(train_images, train_labels)\n",
        "    test_images, test_oh_labels = get_preprocessed_ohe(test_images, test_labels)\n",
        "    \n",
        "    # 학습 데이터를 검증 데이터 세트로 다시 분리\n",
        "    tr_images, val_images, tr_oh_labels, val_oh_labels = train_test_split(train_images, train_oh_labels, test_size=valid_size, random_state=random_state)\n",
        "    \n",
        "    return (tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels ) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gQ4pqDsT1v6"
      },
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "# Fashion MNIST 데이터 재 로딩 및 전처리 적용하여 학습/검증/데이터 세트 생성. \n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "print(train_images.shape, train_labels.shape, test_images.shape, test_labels.shape)\n",
        "(tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels) = \\\n",
        "    get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021)\n",
        "print(tr_images.shape, tr_oh_labels.shape, val_images.shape, val_oh_labels.shape, test_images.shape, test_labels.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vo9SGDhVgsPf"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Model 생성 및 optimizer, loss, metric 적용\n",
        "model = create_model()\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8owUJunhgbc3"
      },
      "source": [
        "# 학습 수행. \n",
        "history = model.fit(x=tr_images, y=tr_oh_labels, batch_size=128, epochs=20, validation_data=(val_images, val_oh_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obGMJtI1gwZX"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def show_history(history):\n",
        "    plt.plot(history.history['accuracy'], label='train')\n",
        "    plt.plot(history.history['val_accuracy'], label='valid')\n",
        "    plt.legend()\n",
        "    \n",
        "show_history(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2As2F3vgzYm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}